{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "“transfer_learning.ipynb”的副本",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bbocwang/Adaptive-Transfer-learning/blob/master/Task1\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h5UuW3cPxSxO",
        "colab_type": "text"
      },
      "source": [
        "# Transfer learning with PyTorch\n",
        "We're going to train a neural network to classify dogs and cats."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vx2jMvYDxSxQ",
        "colab_type": "text"
      },
      "source": [
        "## Init, helpers, utils, ..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tOiWqvXDxSxR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-UpXIFINxSxV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d28945be-75da-4b59-c49d-1dfe467c5c37"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "\n",
        "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "DEVICE"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hAEYJTOcxSxX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pprint import pprint\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from IPython.core.debugger import set_trace"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhP8y6qDxSxZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# %load my_train_helper.py\n",
        "def get_trainable(model_params):\n",
        "    return (p for p in model_params if p.requires_grad)\n",
        "\n",
        "\n",
        "def get_frozen(model_params):\n",
        "    return (p for p in model_params if not p.requires_grad)\n",
        "\n",
        "\n",
        "def all_trainable(model_params):\n",
        "    return all(p.requires_grad for p in model_params)\n",
        "\n",
        "\n",
        "def all_frozen(model_params):\n",
        "    return all(not p.requires_grad for p in model_params)\n",
        "\n",
        "\n",
        "def freeze_all(model_params):\n",
        "    for param in model_params:\n",
        "        param.requires_grad = False\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "toc-hr-collapsed": true,
        "id": "WjhXQ5rIxSxc",
        "colab_type": "text"
      },
      "source": [
        "# The Data - DogsCatsDataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ejaImra3xSxc",
        "colab_type": "text"
      },
      "source": [
        "## Transforms"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5mjcZbEixSxd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchvision import transforms\n",
        "\n",
        "_image_size = 224\n",
        "_mean = [0.485, 0.456, 0.406]\n",
        "_std = [0.229, 0.224, 0.225]\n",
        "\n",
        "\n",
        "train_trans = transforms.Compose([\n",
        "    transforms.Resize(256),  # some images are pretty small\n",
        "    transforms.RandomCrop(_image_size),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ColorJitter(.3, .3, .3),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(_mean, _std),\n",
        "])\n",
        "val_trans = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(_image_size),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(_mean, _std),\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YAGnfG6xxSxg",
        "colab_type": "text"
      },
      "source": [
        "## Dataset\n",
        "\n",
        "The implementation of the dataset does not really."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUphGjnCxSxg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# %load my_datasets.py\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "from torchvision.datasets.folder import ImageFolder, default_loader\n",
        "from torchvision.datasets.utils import download_url, check_integrity\n",
        "\n",
        "\n",
        "################################################################################\n",
        "# PyTorch\n",
        "class DogsCatsDataset(ImageFolder):\n",
        "    \"\"\"\n",
        "    The 'Dogs and Cats' dataset from kaggle.\n",
        "\n",
        "    https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition/\n",
        "\n",
        "    Args:\n",
        "        root: the location where to store the dataset\n",
        "        suffix: path to the train/valid/sample dataset. See folder structure.\n",
        "        transform (callable, optional): A function/transform that takes in\n",
        "            an PIL image and returns a transformed version.\n",
        "            E.g, ``transforms.RandomCrop``\n",
        "        target_transform (callable, optional): A function/transform that\n",
        "            takes in the target and transforms it.\n",
        "        loader: A function to load an image given its path.\n",
        "        download: if ``True``, download the data.\n",
        "\n",
        "\n",
        "    The folder structure of the dataset is as follows::\n",
        "\n",
        "        └── dogscats\n",
        "            ├── sample\n",
        "            │   ├── train\n",
        "            │   │   ├── cats\n",
        "            │   │   └── dogs\n",
        "            │   └── valid\n",
        "            │       ├── cats\n",
        "            │       └── dogs\n",
        "            ├── train\n",
        "            │   ├── cats\n",
        "            │   └── dogs\n",
        "            └── valid\n",
        "                ├── cats\n",
        "                └── dogs\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    url = \"http://files.fast.ai/data/dogscats.zip\"\n",
        "    filename = \"dogscats.zip\"\n",
        "    checksum = \"aef22ec7d472dd60e8ee79eecc19f131\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        root: str,\n",
        "        suffix: str,\n",
        "        transform=None,\n",
        "        target_transform=None,\n",
        "        loader=default_loader,\n",
        "        download=False,\n",
        "    ):\n",
        "        self.root = os.path.expanduser(root)\n",
        "\n",
        "        if download:\n",
        "            self._download()\n",
        "            self._extract()\n",
        "\n",
        "        if not self._check_integrity():\n",
        "            raise RuntimeError(\n",
        "                \"Dataset not found or corrupted. \"\n",
        "                \"You can use download=True to download it\"\n",
        "            )\n",
        "\n",
        "        path = os.path.join(self.root, \"dogscats\", suffix)\n",
        "        print(f\"Loading data from {path}.\")\n",
        "        assert os.path.isdir(path), f\"'{suffix}' is not valid.\"\n",
        "\n",
        "        super().__init__(path, transform, target_transform, loader)\n",
        "\n",
        "    def _download(self):\n",
        "        if self._check_integrity():\n",
        "            print(\"Dataset already downloaded and verified.\")\n",
        "            return\n",
        "\n",
        "        root = self.root\n",
        "        print(\"Downloading dataset... (this might take a while)\")\n",
        "        download_url(self.url, root, self.filename, self.checksum)\n",
        "\n",
        "    def _extract(self):\n",
        "        path_to_zip = os.path.join(self.root, self.filename)\n",
        "        with zipfile.ZipFile(path_to_zip, \"r\") as zip_ref:\n",
        "            zip_ref.extractall(self.root)\n",
        "\n",
        "    def _check_integrity(self):\n",
        "        path_to_zip = os.path.join(self.root, self.filename)\n",
        "        return check_integrity(path_to_zip, self.checksum)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5VPj44RaxSxj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_ds = DogsCatsDataset(\"../data/raw\", \"sample/train\", transform=train_trans)\n",
        "val_ds = DogsCatsDataset(\"../data/raw\", \"sample/valid\", transform=val_trans)\n",
        "\n",
        "batch_size = 2\n",
        "n_classes = 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yms3uQ9zxSxm",
        "colab_type": "text"
      },
      "source": [
        "Use the following if you want to use the full dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_YddAqkYxSxm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train_ds = DogsCatsDataset(\"../data/raw\", \"train\", transform=train_trans)\n",
        "# val_ds = DogsCatsDataset(\"../data/raw\", \"calid\", transform=val_trans)\n",
        "# batch_size = 512"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8EFFRNVxSxt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(train_ds), len(val_ds)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7aq0vqzxSxv",
        "colab_type": "text"
      },
      "source": [
        "## DataLoader\n",
        "Batch loading for datasets with multi-processing and different sample strategies."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0H1KT68xSxw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "\n",
        "train_dl = DataLoader(\n",
        "    train_ds,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=4,\n",
        ")\n",
        "\n",
        "val_dl = DataLoader(\n",
        "    val_ds,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        "    num_workers=4,\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zSQQ5Qj9xSxy",
        "colab_type": "text"
      },
      "source": [
        "# The Model\n",
        "PyTorch offers quite a few [pre-trained networks](https://pytorch.org/docs/stable/torchvision/models.html) such as:\n",
        "- AlexNet\n",
        "- VGG\n",
        "- ResNet\n",
        "- SqueezeNet\n",
        "- DenseNet\n",
        "- Inception v3\n",
        "\n",
        "And there are more available via [pretrained-models.pytorch](https://github.com/Cadene/pretrained-models.pytorch):\n",
        "- NASNet,\n",
        "- ResNeXt,\n",
        "- InceptionV4,\n",
        "- InceptionResnetV2, \n",
        "- Xception, \n",
        "- DPN,\n",
        "- ...\n",
        "\n",
        "We'll use a simple resnet18 model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHdeDgsTxSxz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchvision import models\n",
        "\n",
        "model = models.resnet18(pretrained=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfPbmKeNxSx2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZCSPqm_xSx4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torchsummary\n",
        "\n",
        "torchsummary.summary(model, (3, 224, 224))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "szzBjpBlxSx6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Freeze all parameters manually\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mXc1SgTxSx9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Or use our convenient functions from before\n",
        "freeze_all(model.parameters())\n",
        "assert all_frozen(model.parameters())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wMNhfGEyxSx_",
        "colab_type": "text"
      },
      "source": [
        "Replace the last layer with a linear layer. New layers have `requires_grad = True`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qDeNgMyxSyA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fc = nn.Linear(512, n_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NjlI5JIcxSyD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "assert not all_frozen(model.parameters())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BArA3Yp_xSyH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_model(n_classes=2):\n",
        "    model = models.resnet18(pretrained=True)\n",
        "    freeze_all(model.parameters())\n",
        "    model.fc = nn.Linear(512, n_classes)\n",
        "    model = model.to(DEVICE)\n",
        "    return model\n",
        "\n",
        "\n",
        "model = get_model()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38XvxuutxSyK",
        "colab_type": "text"
      },
      "source": [
        "# The Loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zy5otA9WxSyL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FddJxJimxSyN",
        "colab_type": "text"
      },
      "source": [
        "# The Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qk5bANRBxSyO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = torch.optim.Adam(\n",
        "    get_trainable(model.parameters()),\n",
        "    lr=0.001,\n",
        "    # momentum=0.9,\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mdmJblpNxSyQ",
        "colab_type": "text"
      },
      "source": [
        "# The Train Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zthp-OMYxSyR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "N_EPOCHS = 2\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    print(f\"Epoch {epoch+1}/{N_EPOCHS}\")\n",
        "    \n",
        "    # Train\n",
        "    model.train()  # IMPORTANT\n",
        "    \n",
        "    running_loss, correct = 0.0, 0\n",
        "    for X, y in train_dl:\n",
        "        X, y = X.to(DEVICE), y.to(DEVICE)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        y_ = model(X)\n",
        "        loss = criterion(y_, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        # Statistics\n",
        "        print(f\"    batch loss: {loss.item():0.3f}\")\n",
        "        _, y_label_ = torch.max(y_, 1)\n",
        "        correct += (y_label_ == y).sum().item()\n",
        "        running_loss += loss.item() * X.shape[0]\n",
        "    \n",
        "    print(f\"  Train Loss: {running_loss / len(train_dl.dataset)}\")\n",
        "    print(f\"  Train Acc:  {correct / len(train_dl.dataset)}\")\n",
        "    \n",
        "    \n",
        "    # Eval\n",
        "    model.eval()  # IMPORTANT\n",
        "    \n",
        "    running_loss, correct = 0.0, 0\n",
        "    with torch.no_grad():  # IMPORTANT\n",
        "        for X, y in val_dl:\n",
        "            X, y = X.to(DEVICE), y.to(DEVICE)\n",
        "                    \n",
        "            y_ = model(X)\n",
        "        \n",
        "            # Statistics\n",
        "            _, y_label_ = torch.max(y_, 1)\n",
        "            correct += (y_label_ == y).sum().item()\n",
        "            loss = criterion(y_, y)\n",
        "            running_loss += loss.item() * X.shape[0]\n",
        "    \n",
        "    print(f\"  Valid Loss: {running_loss / len(val_dl.dataset)}\")\n",
        "    print(f\"  Valid Acc:  {correct / len(val_dl.dataset)}\")\n",
        "    print()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RzuEjkmwxSyT",
        "colab_type": "text"
      },
      "source": [
        "# Exercise\n",
        "- Create your own module which takes any imagenet model (uses it unmodified as backbone) and adds a problem specific head."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BqsDNJtAxSyV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Net(nn.module):\n",
        "    def __init__(self, backbone: nn.Module, n_classes: int):\n",
        "        super().__init__()\n",
        "        # self.backbone\n",
        "        # self.head = init_head(n_classes)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        # TODO\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}